{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e308a64",
   "metadata": {},
   "source": [
    "# Chapter 1: What Is Reinforcement Learning?\n",
    "\n",
    "This notebook accompanies Chapter 1 of \"Deep Reinforcement Learning Hands-On\" by Maxim Lapan, exploring the foundational concepts of reinforcement learning and its theoretical framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed343542",
   "metadata": {},
   "source": [
    "## The Reinforcement Learning Framework\n",
    "\n",
    "Reinforcement Learning is built around the interaction between two main entities:\n",
    "\n",
    "- **Agent**: The decision-maker (AI system, robot, etc.) that learns and takes actions\n",
    "- **Environment**: Everything external to the agent that it interacts with\n",
    "\n",
    "These entities communicate through three key channels:\n",
    "\n",
    "1. **Actions**: What the agent chooses to do\n",
    "2. **Observations**: Information the agent receives about the environment state  \n",
    "3. **Reward**: Scalar feedback indicating how well the agent is performing\n",
    "\n",
    "The diagram below illustrates this fundamental RL loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf29d039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 1.2: RL entities and their communication channels\n",
      "\n",
      "Rendering Mermaid diagram...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"text-align: center; margin: 20px;\">\n",
       "    <div class=\"mermaid\" id=\"mermaid-diagram\">\n",
       "\n",
       "graph LR\n",
       "    A[\"ü§ñ<br/>Agent\"] \n",
       "    E[\"üå¥<br/>Environment\"]\n",
       "    \n",
       "    A -->|\"Actions\"| E\n",
       "    E -->|\"Reward\"| A\n",
       "    E -->|\"Observations\"| A\n",
       "    \n",
       "    style A fill:#e1f5fe,stroke:#01579b,stroke-width:3px\n",
       "    style E fill:#f3e5f5,stroke:#4a148c,stroke-width:3px\n",
       "\n",
       "    </div>\n",
       "</div>\n",
       "\n",
       "<script type=\"module\">\n",
       "    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';\n",
       "    mermaid.initialize({ \n",
       "        startOnLoad: true,\n",
       "        theme: 'default',\n",
       "        themeVariables: {\n",
       "            primaryColor: '#e1f5fe',\n",
       "            primaryTextColor: '#01579b',\n",
       "            primaryBorderColor: '#01579b',\n",
       "            lineColor: '#666',\n",
       "            sectionBkColor: '#f3e5f5'\n",
       "        }\n",
       "    });\n",
       "    mermaid.run();\n",
       "</script>\n",
       "\n",
       "<style>\n",
       "    .mermaid {\n",
       "        text-align: center;\n",
       "        font-family: 'Arial', sans-serif;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If the diagram doesn't render above, you can view it at: https://mermaid.live/edit#%0Agraph%20LR%0A%20%20%20%20A%5B%22%F0%9F%A4%96%3Cbr/%3EAgent%22%5D%20%0A%20%20%20%20E%5B%22%F0%9F%8C%B4%3Cbr/%3EEnvironment%22%5D%0A%20%20%20%20%0A%20%20%20%20A%20--%3E%7C%22Actions%22%7C%20E%0A%20%20%20%20E%20--%3E%7C%22Reward%22%7C%20A%0A%20%20%20%20E%20--%3E%7C%22Observations%22%7C%20A%0A%20%20%20%20%0A%20%20%20%20style%20A%20fill%3A%23e1f5fe%2Cstroke%3A%2301579b%2Cstroke-width%3A3px%0A%20%20%20%20style%20E%20fill%3A%23f3e5f5%2Cstroke%3A%234a148c%2Cstroke-width%3A3px%0A\n",
      "\n",
      "Alternatively, try installing mermaid support for Jupyter:\n",
      "pip install jupyterlab-mermaid\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import urllib.parse\n",
    "\n",
    "# Create Mermaid diagram code\n",
    "mermaid_code = \"\"\"\n",
    "graph LR\n",
    "    A[\"ü§ñ<br/>Agent\"] \n",
    "    E[\"üå¥<br/>Environment\"]\n",
    "    \n",
    "    A -->|\"Actions\"| E\n",
    "    E -->|\"Reward\"| A\n",
    "    E -->|\"Observations\"| A\n",
    "    \n",
    "    style A fill:#e1f5fe,stroke:#01579b,stroke-width:3px\n",
    "    style E fill:#f3e5f5,stroke:#4a148c,stroke-width:3px\n",
    "\"\"\"\n",
    "\n",
    "# Method 1: Try direct HTML with better script loading\n",
    "html_content = f\"\"\"\n",
    "<div style=\"text-align: center; margin: 20px;\">\n",
    "    <div class=\"mermaid\" id=\"mermaid-diagram\">\n",
    "{mermaid_code}\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<script type=\"module\">\n",
    "    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';\n",
    "    mermaid.initialize({{ \n",
    "        startOnLoad: true,\n",
    "        theme: 'default',\n",
    "        themeVariables: {{\n",
    "            primaryColor: '#e1f5fe',\n",
    "            primaryTextColor: '#01579b',\n",
    "            primaryBorderColor: '#01579b',\n",
    "            lineColor: '#666',\n",
    "            sectionBkColor: '#f3e5f5'\n",
    "        }}\n",
    "    }});\n",
    "    mermaid.run();\n",
    "</script>\n",
    "\n",
    "<style>\n",
    "    .mermaid {{\n",
    "        text-align: center;\n",
    "        font-family: 'Arial', sans-serif;\n",
    "    }}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "# Alternative method: Use Mermaid Live Editor\n",
    "encoded_diagram = urllib.parse.quote(mermaid_code)\n",
    "mermaid_live_url = f\"https://mermaid.live/edit#{encoded_diagram}\"\n",
    "\n",
    "print(\"Figure 1.2: RL entities and their communication channels\")\n",
    "print(\"\\nRendering Mermaid diagram...\")\n",
    "display(HTML(html_content))\n",
    "\n",
    "print(f\"\\nIf the diagram doesn't render above, you can view it at: {mermaid_live_url}\")\n",
    "print(\"\\nAlternatively, try installing mermaid support for Jupyter:\")\n",
    "print(\"pip install jupyterlab-mermaid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fallback SVG version (always works):\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"600\" height=\"300\" viewBox=\"0 0 600 300\">\n",
       "  <!-- Background -->\n",
       "  <rect width=\"600\" height=\"300\" fill=\"white\"/>\n",
       "  \n",
       "  <!-- Agent Box -->\n",
       "  <rect x=\"50\" y=\"100\" width=\"120\" height=\"80\" rx=\"15\" ry=\"15\" fill=\"#e1f5fe\" stroke=\"#01579b\" stroke-width=\"3\"/>\n",
       "  <text x=\"110\" y=\"125\" text-anchor=\"middle\" font-size=\"24\">ü§ñ</text>\n",
       "  <text x=\"110\" y=\"155\" text-anchor=\"middle\" font-size=\"14\" font-weight=\"bold\">Agent</text>\n",
       "  \n",
       "  <!-- Environment Box -->\n",
       "  <rect x=\"430\" y=\"100\" width=\"120\" height=\"80\" rx=\"15\" ry=\"15\" fill=\"#f3e5f5\" stroke=\"#4a148c\" stroke-width=\"3\"/>\n",
       "  <text x=\"490\" y=\"125\" text-anchor=\"middle\" font-size=\"24\">üå¥</text>\n",
       "  <text x=\"490\" y=\"155\" text-anchor=\"middle\" font-size=\"14\" font-weight=\"bold\">Environment</text>\n",
       "  \n",
       "  <!-- Actions Arrow (top) -->\n",
       "  <defs>\n",
       "    <marker id=\"arrowhead-red\" markerWidth=\"10\" markerHeight=\"7\" refX=\"9\" refY=\"3.5\" orient=\"auto\">\n",
       "      <polygon points=\"0 0, 10 3.5, 0 7\" fill=\"red\"/>\n",
       "    </marker>\n",
       "    <marker id=\"arrowhead-orange\" markerWidth=\"10\" markerHeight=\"7\" refX=\"9\" refY=\"3.5\" orient=\"auto\">\n",
       "      <polygon points=\"0 0, 10 3.5, 0 7\" fill=\"orange\"/>\n",
       "    </marker>\n",
       "    <marker id=\"arrowhead-purple\" markerWidth=\"10\" markerHeight=\"7\" refX=\"9\" refY=\"3.5\" orient=\"auto\">\n",
       "      <polygon points=\"0 0, 10 3.5, 0 7\" fill=\"purple\"/>\n",
       "    </marker>\n",
       "  </defs>\n",
       "  \n",
       "  <!-- Actions curve (top) -->\n",
       "  <path d=\"M 170 120 Q 300 80 430 120\" stroke=\"red\" stroke-width=\"3\" fill=\"none\" marker-end=\"url(#arrowhead-red)\"/>\n",
       "  <text x=\"300\" y=\"70\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"red\">Actions</text>\n",
       "  \n",
       "  <!-- Reward arrow (middle) -->\n",
       "  <line x1=\"430\" y1=\"140\" x2=\"170\" y2=\"140\" stroke=\"orange\" stroke-width=\"3\" marker-end=\"url(#arrowhead-orange)\"/>\n",
       "  <text x=\"300\" y=\"135\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"orange\">Reward</text>\n",
       "  \n",
       "  <!-- Observations curve (bottom) -->\n",
       "  <path d=\"M 430 160 Q 300 200 170 160\" stroke=\"purple\" stroke-width=\"3\" fill=\"none\" marker-end=\"url(#arrowhead-purple)\"/>\n",
       "  <text x=\"300\" y=\"215\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"purple\">Observations</text>\n",
       "  \n",
       "  <!-- Title -->\n",
       "  <text x=\"300\" y=\"30\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"bold\">\n",
       "    Figure 1.2: RL entities and their communication channels\n",
       "  </text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alternative: Clean SVG version that always works\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "svg_diagram = \"\"\"\n",
    "<svg width=\"600\" height=\"300\" viewBox=\"0 0 600 300\" xmlns=\"http://www.w3.org/2000/svg\">\n",
    "  <!-- Background -->\n",
    "  <rect width=\"600\" height=\"300\" fill=\"white\"/>\n",
    "  \n",
    "  <!-- Agent Box -->\n",
    "  <rect x=\"50\" y=\"100\" width=\"120\" height=\"80\" rx=\"15\" ry=\"15\" \n",
    "        fill=\"#e1f5fe\" stroke=\"#01579b\" stroke-width=\"3\"/>\n",
    "  <text x=\"110\" y=\"125\" text-anchor=\"middle\" font-size=\"24\">ü§ñ</text>\n",
    "  <text x=\"110\" y=\"155\" text-anchor=\"middle\" font-size=\"14\" font-weight=\"bold\">Agent</text>\n",
    "  \n",
    "  <!-- Environment Box -->\n",
    "  <rect x=\"430\" y=\"100\" width=\"120\" height=\"80\" rx=\"15\" ry=\"15\" \n",
    "        fill=\"#f3e5f5\" stroke=\"#4a148c\" stroke-width=\"3\"/>\n",
    "  <text x=\"490\" y=\"125\" text-anchor=\"middle\" font-size=\"24\">üå¥</text>\n",
    "  <text x=\"490\" y=\"155\" text-anchor=\"middle\" font-size=\"14\" font-weight=\"bold\">Environment</text>\n",
    "  \n",
    "  <!-- Actions Arrow (top) -->\n",
    "  <defs>\n",
    "    <marker id=\"arrowhead-red\" markerWidth=\"10\" markerHeight=\"7\" \n",
    "            refX=\"9\" refY=\"3.5\" orient=\"auto\">\n",
    "      <polygon points=\"0 0, 10 3.5, 0 7\" fill=\"red\"/>\n",
    "    </marker>\n",
    "    <marker id=\"arrowhead-orange\" markerWidth=\"10\" markerHeight=\"7\" \n",
    "            refX=\"9\" refY=\"3.5\" orient=\"auto\">\n",
    "      <polygon points=\"0 0, 10 3.5, 0 7\" fill=\"orange\"/>\n",
    "    </marker>\n",
    "    <marker id=\"arrowhead-purple\" markerWidth=\"10\" markerHeight=\"7\" \n",
    "            refX=\"9\" refY=\"3.5\" orient=\"auto\">\n",
    "      <polygon points=\"0 0, 10 3.5, 0 7\" fill=\"purple\"/>\n",
    "    </marker>\n",
    "  </defs>\n",
    "  \n",
    "  <!-- Actions curve (top) -->\n",
    "  <path d=\"M 170 120 Q 300 80 430 120\" stroke=\"red\" stroke-width=\"3\" \n",
    "        fill=\"none\" marker-end=\"url(#arrowhead-red)\"/>\n",
    "  <text x=\"300\" y=\"70\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"red\">Actions</text>\n",
    "  \n",
    "  <!-- Reward arrow (middle) -->\n",
    "  <line x1=\"430\" y1=\"140\" x2=\"170\" y2=\"140\" stroke=\"orange\" stroke-width=\"3\" \n",
    "        marker-end=\"url(#arrowhead-orange)\"/>\n",
    "  <text x=\"300\" y=\"135\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"orange\">Reward</text>\n",
    "  \n",
    "  <!-- Observations curve (bottom) -->\n",
    "  <path d=\"M 430 160 Q 300 200 170 160\" stroke=\"purple\" stroke-width=\"3\" \n",
    "        fill=\"none\" marker-end=\"url(#arrowhead-purple)\"/>\n",
    "  <text x=\"300\" y=\"215\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"purple\">Observations</text>\n",
    "  \n",
    "  <!-- Title -->\n",
    "  <text x=\"300\" y=\"30\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"bold\">\n",
    "    Figure 1.2: RL entities and their communication channels\n",
    "  </text>\n",
    "</svg>\n",
    "\"\"\"\n",
    "\n",
    "print(\"Fallback SVG version (always works):\")\n",
    "display(SVG(svg_diagram))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ea707",
   "metadata": {},
   "source": [
    "### Key Characteristics of This Framework\n",
    "\n",
    "This simple diagram captures the essence of all reinforcement learning systems:\n",
    "\n",
    "**üîÑ Continuous Loop**: The agent-environment interaction forms a continuous feedback loop where:\n",
    "- Agent observes the current state\n",
    "- Agent selects and executes an action\n",
    "- Environment transitions to a new state\n",
    "- Environment provides reward and new observations\n",
    "- Process repeats\n",
    "\n",
    "**üìä Learning Signal**: Unlike supervised learning (which uses labeled examples) or unsupervised learning (which finds patterns without labels), RL uses the **reward signal** as the primary learning mechanism.\n",
    "\n",
    "**üéØ Goal**: The agent's objective is to learn a **policy** (strategy for selecting actions) that maximizes the cumulative reward over time.\n",
    "\n",
    "**‚öñÔ∏è Exploration vs Exploitation**: The agent must balance:\n",
    "- **Exploitation**: Using current knowledge to get rewards\n",
    "- **Exploration**: Trying new actions to potentially discover better strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12fdc79",
   "metadata": {},
   "source": [
    "### Examples in Practice\n",
    "\n",
    "Let's see how this framework applies to different domains:\n",
    "\n",
    "| Domain | Agent | Environment | Actions | Observations | Reward |\n",
    "|--------|-------|-------------|---------|-------------|---------|\n",
    "| **üéÆ Game Playing** | AI player | Game world | Button presses, moves | Screen pixels, game state | Score changes |\n",
    "| **ü§ñ Robotics** | Robot | Physical world | Motor commands | Sensor readings | Task completion |\n",
    "| **üí∞ Trading** | Trading algorithm | Financial markets | Buy/sell orders | Market data, prices | Profit/loss |\n",
    "| **üß† LLM Training** | Language model | Text environment | Token predictions | Previous tokens | Human feedback scores |\n",
    "| **üöó Autonomous Driving** | Driving AI | Road environment | Steering, acceleration | Camera, sensors | Safe arrival |\n",
    "\n",
    "This framework's generality is what makes RL so powerful - the same mathematical foundations apply whether we're training a chess AI or teaching a robot to walk!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avpc-off-vehicle-qa-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
